{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample project: stock prediction and trading\n",
    "\n",
    "What question you are looking to answer?\n",
    "Why does this question matter?\n",
    "What data did you use?\n",
    "Where you got the data?\n",
    "How was the data sampled?\n",
    "How was the data obtained?\n",
    "How did you explore the data?\n",
    "How did you model the data?\n",
    "Why you chose to model it that way?\n",
    "What code did you write / use?\n",
    "How did you fit the model?\n",
    "How did you validated the model?\n",
    "How you know the results make sense?\n",
    "How did you visualized the results?\n",
    "How you would communicate the results to others?\n",
    "What did you learn?\n",
    "What you would do differently if you did this project again?\n",
    "If you were going to continue this work, what next steps you would take with this project?\n",
    "How you would explain what you did to a data scientist?\n",
    "How you would explain what you did to a non-data scientist?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvements yet to be done\n",
    "\n",
    "Asdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Configure logging, import config, and connect to database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s %(message)s', datefmt='%H:%M:%S')\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import sklearn\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "sns.set(rc={'figure.figsize': (16, 9)})\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import config\n",
    "from data.database import Database\n",
    "from data.api_manager import APIManager\n",
    "from utils import descriptive_stats\n",
    "from utils import performance_metrics\n",
    "\n",
    "db = Database(config.database)\n",
    "api = APIManager(config.api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch trades from API\n",
    "\n",
    "Fetch all trades for the ticker of interest for a range of dates and store them in the database. Only fetch trades that are not already stored in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:25:05 Fetching 0 days of MSFT trades.\n"
     ]
    }
   ],
   "source": [
    "ticker = 'MSFT'\n",
    "date_from = '2015-01-01'\n",
    "date_to = '2020-12-31'\n",
    "\n",
    "ticker_details = db.get_ticker_details(ticker)\n",
    "if ticker_details is None:\n",
    "    ticker_details = db.store_ticker_details(api.get_ticker_details(ticker))\n",
    "\n",
    "dates_with_trades = db.get_open_dates(ticker_details['exchange'], date_from, date_to)\n",
    "dates_already_stored = db.get_stored_dates('trades', ticker)\n",
    "dates_to_fetch = [d for d in dates_with_trades if d not in dates_already_stored]\n",
    "\n",
    "logging.info(f'Fetching {len(dates_to_fetch)} days of {ticker} trades.')\n",
    "for date in dates_to_fetch:\n",
    " \n",
    "    # Download trades.\n",
    "    time_before_fetch = time.time()\n",
    "    trades = api.get_daily_trades(ticker, date) #quotes: api.get_daily_quotes()\n",
    "\n",
    "    # Store trades in database.\n",
    "    time_before_store = time.time()\n",
    "    db.store_trades(ticker, date, trades) #quotes: db.store_quotes()\n",
    "\n",
    "    logging.info(\n",
    "        f'{ticker} {date} - '\n",
    "        f'fetch time: {int(round(time_before_store - time_before_fetch))}s, '\n",
    "        f'store time: {int(round(time.time() - time_before_store))}s'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The target variable\n",
    "\n",
    "If we know everything about the future, how do we decide when to buy and sell to optimise profits? What time window should we operate within to take advantage of ups and downs? How much does the price have to increase for transaction to be profitable? \n",
    "\n",
    "Each timepoint can be classified as `buy`, `keep`, or `sell`:\n",
    "\n",
    "- `buy`: The price is increasing, and it will increase enough to offset the transaction cost. The stock should be bought.\n",
    "- `sell`: The price is decreasing. The stock should be sold.\n",
    "- `keep`: The price is neither increasing nor decreasing signficantly. The stock should not bought, but it should also not be sold if it is owned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "For every `n` seconds during open hours, calculate target price and features. For now, `n` is set to `1`. Features are stored back in the database as they can take a while to calculate. \n",
    "\n",
    "Feature ideas:\n",
    "\n",
    "- Summary stats of previous prices and volumes (https://alphascientist.com/feature_engineering.html).\n",
    "- Trading markers (https://blog.roboforex.com/blog/2020/01/10/creating-a-trading-strategies-based-on-the-mean-reversion-and-momentum/).\n",
    "- Stats on quotes.\n",
    "- Relevant news articles.\n",
    "- Mentions on social networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stats_per_second(trades, time_from, time_to):\n",
    "    \"\"\" Calculate descriptive stats for trades for every second.\n",
    "    \n",
    "    Stats are calculated in the second _before_ the time listed to prevent\n",
    "    future data leakage.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    time_period = pd.date_range(time_from, time_to, freq='1S')\n",
    "    \n",
    "    grouper = pd.Grouper(key='time', freq='1S')\n",
    "    trades_grouped = trades.groupby(grouper)\n",
    "    \n",
    "    price_stats = trades_grouped['price'].agg(\n",
    "        ['count', 'mean', 'median', 'min', 'max', 'std']\n",
    "    )\n",
    "    price_mean_weighted = weighted_mean(trades, 'price', 'volume', grouper)\n",
    "    \n",
    "    volume_stats = trades_grouped['volume'].agg(\n",
    "        ['sum', 'mean', 'median', 'min', 'max', 'std']\n",
    "    )\n",
    "    \n",
    "    \n",
    "    stats = pd.DataFrame(index=time_period) \\\n",
    "        .join(price_mean_weighted, how='left') \\\n",
    "        .join(price_stats.add_prefix('price_'), how='left') \\\n",
    "        .join(volume_stats.add_prefix('volume_'), how='left') \\\n",
    "    \n",
    "    return stats\n",
    "\n",
    "ticker = 'MSFT'\n",
    "exchange = db.get_ticker_details(ticker)['exchange']\n",
    "\n",
    "stored_dates = sorted(db.get_stored_dates('trades', ticker))\n",
    "open_hours = db.get_open_hours(stored_dates, exchange)\n",
    "\n",
    "for date in [stored_dates[4], stored_dates[100]]:\n",
    "    \n",
    "    trades = db.get_trades(ticker, date)\n",
    "    print(trades.iloc[0]['time'], trades.iloc[-1]['time'])\n",
    "    \n",
    "    open_time, close_time = open_hours[date]\n",
    "    \n",
    "    prices = stats_per_second(\n",
    "        trades, \n",
    "        datetime.datetime.combine(date, open_time), \n",
    "        datetime.datetime.combine(date, close_time)\n",
    "    )\n",
    "\n",
    "\n",
    "#     prices = trades.groupby(period_grouper)['price'].median()\n",
    "#     # Propegate last valid observation forward.\n",
    "#     prices = prices.fillna(method='ffill')\n",
    "\n",
    "prices.iloc[5000:].head(20).fillna(method='ffill')\n",
    "# prices[prices> 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices.iloc[5000:].head(20).fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target variable\n",
    "The future price to predict. The variable classified into either `buy`, `don't sell`, or `sell` depending on the relative increase from the current price to the price in `m` seconds. For now, `m` is set to `5`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'MSFT'\n",
    "exchange = db.get_ticker_details(ticker)['exchange']\n",
    "\n",
    "frequency = '1S' # 1 second\n",
    "\n",
    "stored_dates = sorted(db.get_stored_dates('trades', ticker))\n",
    "\n",
    "\n",
    "trades\n",
    "\n",
    "for date in stored_dates[::-1]:\n",
    "    \n",
    "    # Determine open hours (by Robinhood/Alpaca)\n",
    "\n",
    "    trades = pd.DataFrame(\n",
    "        db.get_trades(ticker, date), \n",
    "        columns=['timestamp', 'price', 'volume']\n",
    "    )\n",
    "    trades['time'] = pd.to_datetime(trades['timestamp']) - pd.DateOffset(hours=5) # America/New Yow\n",
    "    \n",
    "    price_index = pd.date_range(\n",
    "        datetime.datetime.combine(date, start_time),\n",
    "        datetime.datetime.combine(date, close_time),\n",
    "        freq=frequency,\n",
    "        closed='left'\n",
    "    )\n",
    "    \n",
    "    prices = pd.DataFrame(index=price_index).merge(\n",
    "        trades.groupby(pd.Grouper(key='time', freq=frequency))['price'].median(),\n",
    "        how='left',\n",
    "        left_index=True,\n",
    "        right_index=True\n",
    "    )\n",
    "    \n",
    "    # Propegate last valid observation forward.\n",
    "    prices = prices.fillna(method='ffill')\n",
    "\n",
    "    break\n",
    "    \n",
    "prices\n",
    "\n",
    "description = 'Price'\n",
    "db.store_feature(ticker, 'target', prices, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check features for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "\n",
    "- Feature time window\n",
    "- Target variable future time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

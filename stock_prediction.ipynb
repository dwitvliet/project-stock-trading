{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample project: stock prediction and trading\n",
    "\n",
    "_Goal: to predict the price of a stock in the near future._\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Configure logging, import config, and connect to database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import config\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(message)s', datefmt='%H:%M:%S')\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "from data.database import Database\n",
    "from data.api_manager import API_Manager\n",
    "\n",
    "db = Database(config.database)\n",
    "api = API_Manager(config.api_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch trades from API\n",
    "\n",
    "Fetch all trades for ticker within date range and store them in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01:37:08 Fetching 1 days of MSFT trades.\n",
      "01:37:11 MSFT 2015-01-02 - fetch time: 1s, store time: 2s\n"
     ]
    }
   ],
   "source": [
    "ticker = 'MSFT'\n",
    "date_from = '2015-01-01'\n",
    "date_to = '2015-01-02' #'2020-12-31'\n",
    "bar_frequency = '1S' # 1 second\n",
    "\n",
    "ticker_details = db.get_ticker_details(ticker)\n",
    "if ticker_details is None:\n",
    "    ticker_details = db.store_ticker_details(api.get_ticker_details(ticker))\n",
    "\n",
    "dates_with_trades = db.get_open_dates(ticker_details['exchange'], date_from, date_to)\n",
    "dates_already_stored = db.get_stored_dates('trades', ticker)\n",
    "dates_to_fetch = [d for d in dates_with_trades if d not in dates_already_stored]\n",
    "\n",
    "logging.info(f'Fetching {len(dates_to_fetch)} days of {ticker} trades.')\n",
    "for date in dates_to_fetch:\n",
    "    \n",
    "    # Download raw trades.\n",
    "    time_before_fetch = time.time()\n",
    "    trades = api.get_daily_trades(ticker, date)\n",
    "    \n",
    "    # Process date to calculate bars from raw trades.\n",
    "    time_before_process = time.time()\n",
    "    trades = pd.DataFrame(trades)[['t', 'p', 's']]\n",
    "    trades = trades.rename(columns={'t': 'timestamp', 'p': 'price', 's': 'volume'})\n",
    "    \n",
    "    trades['time'] = pd.to_datetime(trades['timestamp']) - pd.DateOffset(hours=5) # America/New Yow\n",
    "    trades_grouped = trades.groupby(\n",
    "        pd.Grouper(key='time', freq=bar_frequency, sort=True)\n",
    "    )\n",
    "    def get_weighted_bars(x):\n",
    "        cols = ['mean', 'median', 'std']\n",
    "        if not any(x['volume']):\n",
    "            return pd.Series([np.nan, np.nan, np.nan], index=cols)\n",
    "        weighted = np.concatenate([[r.price] * r.volume for r in x.itertuples()])\n",
    "        return pd.Series(\n",
    "            [np.mean(weighted), np.median(weighted), np.std(weighted)], \n",
    "            index=cols\n",
    "        )\n",
    "    price_bars = trades_grouped['price'].agg(['count', 'mean', 'median', 'min', 'max', 'std'])\n",
    "    price_bars_weighted = trades_grouped.apply(get_weighted_bars)\n",
    "    volume_vars = trades_grouped['volume'].agg(['sum', 'mean', 'median', 'min', 'max', 'std'])\n",
    "    \n",
    "    # Store raw trades and bars in database.\n",
    "    time_before_store = time.time()\n",
    "    db.store_trades(ticker, date, trades)\n",
    "    \n",
    "    time_to_fetch = int(round(time_before_process - time_before_fetch))\n",
    "    time_to_process = int(round(time_before_store - time_before_process))\n",
    "    time_to_store = int(round(time.time() - time_before_store))\n",
    "    logging.info(\n",
    "        f'{ticker} {date} - '\n",
    "        f'fetch time: {time_to_fetch}s, '\n",
    "        f'process time: {time_to_process}s, '\n",
    "        f'store time: {time_to_store}s'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.26710557937622"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_weighted_bars(x):\n",
    "    cols = ['mean', 'median', 'std']\n",
    "    if not any(x['volume']):\n",
    "        return pd.Series([np.nan, np.nan, np.nan], index=cols)\n",
    "    weighted = np.concatenate([[r.price] * r.volume for r in x.itertuples()])\n",
    "    return pd.Series(\n",
    "        [np.mean(weighted), np.median(weighted), np.std(weighted)], \n",
    "        index=cols\n",
    "    )\n",
    "a = time.time()\n",
    "price_bars_weighted = trades_grouped.apply(get_weighted_bars)\n",
    "time.time()-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.798645734786987"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try for mean https://stackoverflow.com/questions/26205922/calculate-weighted-average-using-a-pandas-dataframe\n",
    "# Try for median https://stackoverflow.com/questions/29678166/pandas-weighted-median-of-grouped-observations\n",
    "# For std, make own function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "For every `n` seconds during open hours, calculate target price and features. For now, `n` is set to `1`. Features are stored back in the database as they can take a while to calculate. \n",
    "\n",
    "Feature ideas:\n",
    "\n",
    "- Summary stats of previous prices and volumes (https://alphascientist.com/feature_engineering.html).\n",
    "- Trading markers (https://blog.roboforex.com/blog/2020/01/10/creating-a-trading-strategies-based-on-the-mean-reversion-and-momentum/).\n",
    "- Stats on quotes.\n",
    "- Relevant news articles.\n",
    "- Mentions on social networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iuhn(frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target variable\n",
    "The future price to predict. The variable classified into either `buy`, `don't sell`, or `sell` depending on the relative increase from the current price to the price in `m` seconds. For now, `m` is set to `5`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'MSFT'\n",
    "exchange = db.get_ticker_details(ticker)['exchange']\n",
    "\n",
    "frequency = '1S' # 1 second\n",
    "\n",
    "stored_dates = sorted(db.get_stored_dates('trades', ticker))\n",
    "holidays = dict(db.get_holidays(exchange))\n",
    "\n",
    "trades\n",
    "\n",
    "for date in stored_dates[::-1]:\n",
    "    \n",
    "    # Determine open hours (by Robinhood/Alpaca)\n",
    "    halfday = (date in holidays and holidays[date] == 'half')\n",
    "    start_time = datetime.time(9, 0) \n",
    "    close_time = datetime.time(15 if halfday else 18, 0)\n",
    "    \n",
    "    trades = pd.DataFrame(\n",
    "        db.get_trades(ticker, date), \n",
    "        columns=['timestamp', 'price', 'volume']\n",
    "    )\n",
    "    trades['time'] = pd.to_datetime(trades['timestamp']) - pd.DateOffset(hours=5) # America/New Yow\n",
    "    \n",
    "    price_index = pd.date_range(\n",
    "        datetime.datetime.combine(date, start_time),\n",
    "        datetime.datetime.combine(date, close_time),\n",
    "        freq=frequency,\n",
    "        closed='left'\n",
    "    )\n",
    "    \n",
    "    prices = pd.DataFrame(index=price_index).merge(\n",
    "        trades.groupby(pd.Grouper(key='time', freq=frequency))['price'].median(),\n",
    "        how='left',\n",
    "        left_index=True,\n",
    "        right_index=True\n",
    "    )\n",
    "    \n",
    "    # Propegate last valid observation forward.\n",
    "    prices = prices.fillna(method='ffill')\n",
    "\n",
    "    break\n",
    "    \n",
    "prices\n",
    "\n",
    "description = 'Price'\n",
    "db.store_feature(ticker, 'target', prices, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check features for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "\n",
    "- Feature time window\n",
    "- Target variable future time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

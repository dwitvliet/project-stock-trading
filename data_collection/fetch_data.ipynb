{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import time\n",
    "import time\n",
    "import datetime\n",
    "import logging\n",
    "import requests\n",
    "import contextlib\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import config\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(message)s', datefmt='%H:%M:%S')\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "%run database.ipynb # import Database class\n",
    "\n",
    "db = Database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFetcher:\n",
    "    \"\"\" Fetch market data and historical data from the Polygon API.\n",
    "    \n",
    "    The frequency of requests is capped to avoid going beyond what Polygon \n",
    "    permits. The request is stalled upon reaching the maximum allowed frequency.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    MAX_REQUEST_PER_MINUTE = 200\n",
    "    STALL_TIME_UPON_MAX_REQUESTS = 3\n",
    "    MAX_ATTEMPTS = 5\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._recent_requests = []\n",
    "        \n",
    "    def _request(self, url, params={}, attempts_left=DataFetcher.MAX_ATTEMPTS):\n",
    "        params['apiKey'] = config.api_key\n",
    "        result = requests.get(f'https://api.polygon.io{url}', params=params)\n",
    "\n",
    "        if result.status_code == 200:\n",
    "            json = result.json()\n",
    "            if json.get('success', True):\n",
    "                return json\n",
    "        \n",
    "        if attempts_left == 0:\n",
    "            return None\n",
    "        \n",
    "        logging.error(\n",
    "            f'Could not complete request {url} '\n",
    "            f'(Error: {result.status_code}, attempts left: {attempts_left})'\n",
    "        )\n",
    "        time.sleep(5)\n",
    "        return self._request(url, params, attempts_left-1)\n",
    "    \n",
    "    def get_ticker_details(self, ticker):\n",
    "        # https://polygon.io/docs/get_v1_meta_symbols__stocksTicker__company_anchor\n",
    "        url = f'/v1/meta/symbols/{ticker}/company'\n",
    "        return self._request(url)\n",
    "    \n",
    "    \n",
    "    def get_daily_trades(self, ticker, date, start_time=0):\n",
    "        # https://polygon.io/docs/get_v2_ticks_stocks_trades__ticker___date__anchor\n",
    "        \n",
    "        TRADES_PER_REQUEST = 50000\n",
    "        \n",
    "        if type(date) == datetime.date:\n",
    "            date = date.strftime('%Y-%m-%d')\n",
    "            \n",
    "        url = f'/v2/ticks/stocks/trades/{ticker}/{date}'\n",
    "        params = {\n",
    "            'timestamp': start_time,\n",
    "            'limit': TRADES_PER_REQUEST\n",
    "        }\n",
    "\n",
    "        response = self._request(url, params)\n",
    "        if response is None:\n",
    "            return None\n",
    "\n",
    "        # Exclude first trade in responses as it was already present in the \n",
    "        # previous request.\n",
    "        trades = response['results'][int(start_time > 0):]\n",
    "\n",
    "        # Repeat requests until all daily trades have been fetched.\n",
    "        if response['results_count'] >= TRADES_PER_REQUEST:\n",
    "            trades.extend(self.get_daily_trades(ticker, date, start_time=trades[-1]['t']))\n",
    "        \n",
    "        return trades\n",
    "        \n",
    "        \n",
    "api = DataFetcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:26:40 Fetching 14 days of MSFT trades.\n",
      "23:26:50 MSFT 2018-12-11 - fetch time: 6s, store time: 3s\n",
      "23:26:57 MSFT 2018-12-12 - fetch time: 5s, store time: 3s\n"
     ]
    }
   ],
   "source": [
    "ticker = 'MSFT'\n",
    "date_from = '2018-12-01'\n",
    "date_to = '2018-12-31'\n",
    "\n",
    "ticker_details = db.get_ticker_details(ticker)\n",
    "if ticker_details is None:\n",
    "    ticker_details = db.store_ticker_details(api.get_ticker_details(ticker))\n",
    "\n",
    "dates_with_trades = db.get_open_dates(ticker_details['exchange'], date_from, date_to)\n",
    "dates_already_stored = db.get_stored_dates('trades', ticker)\n",
    "dates_to_fetch = [d for d in dates_with_trades if d not in dates_already_stored]\n",
    "\n",
    "logging.info(f'Fetching {len(dates_to_fetch)} days of {ticker} trades.')\n",
    "for date in dates_to_fetch:\n",
    "    \n",
    "    time_before_fetch = time.time()\n",
    "    trades = api.get_daily_trades(ticker, date)\n",
    "    \n",
    "    time_before_store = time.time()\n",
    "    db.store_trades(ticker, date, trades)\n",
    "    \n",
    "    time_to_fetch = int(round(time_before_store - time_before_fetch))\n",
    "    time_to_store = int(round(time.time() - time_before_store))\n",
    "    logging.info(f'{ticker} {date} - fetch time: {time_to_fetch}s, store time: {time_to_store}s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
